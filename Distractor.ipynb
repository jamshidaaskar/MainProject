{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential,Model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meals can be served</td>\n",
       "      <td>in rooms at 9:00 p. m.</td>\n",
       "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>The local government can deal with the problem...</td>\n",
       "      <td>'If some tragedies occur again ', ' relevant d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The author called Tommy 's parents in order to</td>\n",
       "      <td>help them realize their influence on Tommy</td>\n",
       "      <td>'blame Tommy for his failing grades', 'blame T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>the writer is not very willing to use idioms</td>\n",
       "      <td>'idioms are the most important part in a langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can we deal with snake wounds according to...</td>\n",
       "      <td>Stay calm and do n't move .</td>\n",
       "      <td>'Cut the wound and suck the poison out .'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                                Meals can be served   \n",
       "1           It can be inferred from the passage that   \n",
       "2     The author called Tommy 's parents in order to   \n",
       "3           It can be inferred from the passage that   \n",
       "4  How can we deal with snake wounds according to...   \n",
       "\n",
       "                                         answer_text  \\\n",
       "0                             in rooms at 9:00 p. m.   \n",
       "1  The local government can deal with the problem...   \n",
       "2         help them realize their influence on Tommy   \n",
       "3       the writer is not very willing to use idioms   \n",
       "4                        Stay calm and do n't move .   \n",
       "\n",
       "                                          distractor  \n",
       "0  'outside the room at 3:00 p. m.', 'in the dini...  \n",
       "1  'If some tragedies occur again ', ' relevant d...  \n",
       "2  'blame Tommy for his failing grades', 'blame T...  \n",
       "3  'idioms are the most important part in a langu...  \n",
       "4          'Cut the wound and suck the poison out .'  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.values\n",
    "answers = {}\n",
    "distractors = {}\n",
    "count = 0\n",
    "for x in range(train.shape[0]):\n",
    "    answers[train[x][0]] = train[x][1]\n",
    "    a=[]\n",
    "    for y in train[x][2].split(\", \"):\n",
    "        a.append(str(y[1:-1]))\n",
    "    distractors[train[x][0]] = a\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outside the room at 3:00 p. m.',\n",
       " 'in the dining - room at 6:00 p. m.',\n",
       " 'in the dining - room from 7:30 a. m. to 9:15 p. m.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distractors[\"Meals can be served\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-z0-9]+\",\" \" , sentence)\n",
    "    sentence = sentence.split()\n",
    "\n",
    "    sentence = [s for s in sentence if((len(s)>1) or (re.match(\"[0-9]+\",s) is not None))]\n",
    "    sentence = \" \".join(sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all the captions\n",
    "a={}\n",
    "d={}\n",
    "for key , dist_list in distractors.items():\n",
    "    for i in range(len(dist_list)):\n",
    "        dist_list[i] = clean_text(dist_list[i])\n",
    "    answer=clean_text(answers[key])\n",
    "    key=clean_text(key)\n",
    "    a[key]=answer\n",
    "    d[key]=dist_list\n",
    "answers=a\n",
    "distractors=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outside the room at 3 00',\n",
       " 'in the dining room at 6 00',\n",
       " 'in the dining room from 7 30 to 9 15']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distractors[\"meals can be served\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answers.txt\",\"w\") as f:\n",
    "    f.write(str(answers))\n",
    "with open(\"distractors.txt\",\"w\") as f:\n",
    "    f.write(str(distractors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21459\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for key in answers.keys():\n",
    "    [vocab.update(key.split())]\n",
    "    [vocab.update(answers[key].split())]\n",
    "    [vocab.update(sentence.split()) for sentence in distractors[key]]\n",
    "\n",
    "    \n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718584\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "for key in answers.keys():\n",
    "    [total.append(i) for i in key.split()]\n",
    "    [total.append(i) for i in answers[key].split()]\n",
    "    [total.append(i) for des in distractors[key] for i in des.split()]\n",
    "\n",
    "print(len(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4723\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter(total)\n",
    "freq_cnt = dict(counter)\n",
    "\n",
    "sorted_freq_cnt = sorted(freq_cnt.items(),reverse = True,key = lambda x:x[1])\n",
    "\n",
    "threshold =10\n",
    "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
    "total_words = [x[0] for x in sorted_freq_cnt]\n",
    "print(len(sorted_freq_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StartSeq outside the room at 3 00 EndSeq', 'StartSeq in the dining room at 6 00 EndSeq', 'StartSeq in the dining room from 7 30 to 9 15 EndSeq']\n"
     ]
    }
   ],
   "source": [
    "train_distractors = {}\n",
    "for key in distractors.keys():\n",
    "    train_distractors[key] = []\n",
    "    for dist in distractors[key]:\n",
    "        dist_to_append = \"StartSeq \" + dist + \" EndSeq\"\n",
    "        train_distractors[key].append(dist_to_append)\n",
    "        \n",
    "print(train_distractors[\"meals can be served\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4723"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4723"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "for i,word in enumerate(total_words):\n",
    "    word_to_idx[word] = i+1\n",
    "    idx_to_word[i+1] = word\n",
    "    \n",
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx[\"StartSeq\"]=4724\n",
    "idx_to_word[4724] = \"StartSeq\"\n",
    "\n",
    "word_to_idx[\"EndSeq\"]=4725\n",
    "idx_to_word[4725] = \"EndSeq\"\n",
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "vocab_size= vocab_size+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4726"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "for key in train_distractors.keys():\n",
    "    for dist in train_distractors[key]:\n",
    "        max_len = max(max_len,len(dist.split()))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "max_q=0\n",
    "for key in train_distractors.keys():\n",
    "    max_q = max(max_q,len(key.split()))\n",
    "print(max_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "max_a = 0\n",
    "for key in answers.keys():\n",
    "    max_a = max(max_a,len(answers[key].split()))\n",
    "print(max_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(train_distractors,answers,word_to_idx,max_len,batch_size):\n",
    "    X1,X2,X3,y = [],[],[],[]\n",
    "\n",
    "    n=0\n",
    "    while True:\n",
    "        for key,dist_list in train_distractors.items():\n",
    "            n+=1\n",
    "\n",
    "            question = key\n",
    "            answer = answers[key]\n",
    "\n",
    "\n",
    "            seqq = [word_to_idx[wordQ] for wordQ in question.split() if wordQ in word_to_idx]\n",
    "            question= pad_sequences([seqq],maxlen=max_q,value=0,padding='post')[0]\n",
    "\n",
    "\n",
    "            seqa = [word_to_idx[wordA] for wordA in answer.split() if wordA in word_to_idx]\n",
    "            answer = pad_sequences([seqa],maxlen=max_a,value=0,padding='post')[0]\n",
    "\n",
    "            for dist in dist_list:\n",
    "                seq = [word_to_idx[word] for word in dist.split() if word in word_to_idx]\n",
    "                for i in range(1,len(seq)):\n",
    "                    xi = seq[0:i]\n",
    "                    yi = seq[i]\n",
    "\n",
    "                    xi = pad_sequences([xi],maxlen=max_len,value = 0,padding='post')[0] \n",
    "                    yi = to_categorical([yi],num_classes = vocab_size)[0]\n",
    "\n",
    "\n",
    "\n",
    "                    X1.append(question)\n",
    "                    X2.append(answer)\n",
    "                    X3.append(xi)\n",
    "                    y.append(yi)\n",
    "                if n==batch_size:\n",
    "                    yield[[np.array(X1),np.array(X2),np.array(X3)],np.array(y)]\n",
    "                    X1,X2,X3,y = [],[],[],[]\n",
    "                    n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"glove.6B.100d.txt\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "for line in f:\n",
    "  values=line.split()\n",
    "  word = values[0]\n",
    "  embedding_index[word]=np.array(values[1:],dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5985   , -0.46321  ,  0.13001  , -0.019576 ,  0.4603   ,\n",
       "       -0.3018   ,  0.8977   , -0.65634  ,  0.66858  , -0.49164  ,\n",
       "        0.037557 , -0.050889 ,  0.6451   , -0.53882  , -0.3765   ,\n",
       "       -0.04312  ,  0.51384  ,  0.17783  ,  0.28596  ,  0.92063  ,\n",
       "       -0.49349  , -0.48583  ,  0.61321  ,  0.78211  ,  0.19254  ,\n",
       "        0.91228  , -0.055596 , -0.12512  , -0.65688  ,  0.068557 ,\n",
       "        0.55629  ,  1.611    , -0.0073642, -0.48879  ,  0.45493  ,\n",
       "        0.96105  , -0.063369 ,  0.17432  ,  0.9814   , -1.3125   ,\n",
       "       -0.15801  , -0.54301  , -0.13888  , -0.26146  , -0.3691   ,\n",
       "        0.26844  , -0.24375  , -0.19484  ,  0.62583  , -0.7377   ,\n",
       "        0.38351  , -0.75004  , -0.39053  ,  0.091498 , -0.36591  ,\n",
       "       -1.4715   , -0.45228  ,  0.2256   ,  1.1412   , -0.38526  ,\n",
       "       -0.06716  ,  0.57288  , -0.39191  ,  0.31302  , -0.29235  ,\n",
       "       -0.96157  ,  0.15154  , -0.21659  ,  0.25103  ,  0.096967 ,\n",
       "        0.2843   ,  1.4296   , -0.50565  , -0.51374  , -0.47218  ,\n",
       "        0.32036  ,  0.023149 ,  0.22623  , -0.09725  ,  0.82126  ,\n",
       "        0.92599  , -1.0086   , -0.38639  ,  0.86408  , -1.206    ,\n",
       "       -0.28528  ,  0.2265   , -0.38773  ,  0.40879  ,  0.59303  ,\n",
       "        0.30769  ,  0.83804  , -0.63655  , -0.44639  , -0.43406  ,\n",
       "       -0.79364  , -0.28675  , -0.034398 ,  1.3431   ,  0.34904  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddingMatrix():\n",
    "    emb_dim=100\n",
    "    matrix = np.zeros((vocab_size,emb_dim))\n",
    "    for word,idx in word_to_idx.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            matrix[idx] = embedding_vector\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4726, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = getEmbeddingMatrix()\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[4724]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vyshak/anaconda3/envs/tensornlp/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/vyshak/anaconda3/envs/tensornlp/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "input_dist = Input(shape = (max_len,))\n",
    "input_dist1=  Embedding(input_dim=vocab_size,output_dim=100,mask_zero=True)(input_dist)\n",
    "input_dist2 = Dropout(0.3)(input_dist1)\n",
    "input_dist3 = LSTM(256)(input_dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ques = Input(shape = (max_q,))\n",
    "input_ques1=  Embedding(input_dim=vocab_size,output_dim=100,mask_zero=True)(input_ques)\n",
    "input_ques2 = Dropout(0.3)(input_ques1)\n",
    "input_ques3 = LSTM(256)(input_ques2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ans = Input(shape = (max_a,))\n",
    "input_ans1=  Embedding(input_dim=vocab_size,output_dim=100,mask_zero=True)(input_ans)\n",
    "input_ans2 = Dropout(0.3)(input_ans1)\n",
    "input_ans3 = LSTM(256)(input_ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder1 = add([input_dist3,input_ques3,input_ans3])\n",
    "decoder2 = Dense(512 ,activation = 'relu')(decoder1)\n",
    "outputs = Dense(vocab_size,activation= 'softmax')(decoder2)\n",
    "\n",
    "model = Model(inputs = [input_ques,input_ans,input_dist],outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 48)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 101)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 100)      472600      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 48, 100)      472600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 101, 100)     472600      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 100)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 48, 100)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 101, 100)     0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          365568      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 256)          365568      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 256)          365568      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          131584      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4726)         2424438     dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,070,526\n",
      "Trainable params: 5,070,526\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[3].set_weights([embedding_matrix])\n",
    "model.layers[3].trainable = False  \n",
    "\n",
    "model.layers[4].set_weights([embedding_matrix])\n",
    "model.layers[4].trainable = False  \n",
    "model.layers[5].set_weights([embedding_matrix])\n",
    "model.layers[5].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.load_weights(\"./model_weights/model_19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f6f3322e1d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20\n",
    "number_of_ques = 64\n",
    "steps = len(train_distractors)//number_of_ques\n",
    "\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_distractors,answers,word_to_idx,max_len,number_of_ques)\n",
    "    model.fit_generator(generator,epochs=1,steps_per_epoch = steps,verbose = 1)\n",
    "    model.save(\"./model_weights/model_\"+str(i)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_t = {}\n",
    "count = 0\n",
    "for x in range(test.shape[0]):\n",
    "    answers_t[test[x][0]] = test[x][1]\n",
    "    count = count+1\n",
    "    \n",
    "a={}\n",
    "for key , answer in answers_t.items():\n",
    "    answer=clean_text(answers_t[key])\n",
    "    key=clean_text(key)\n",
    "    a[key]=answer\n",
    "answers_t=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lack of water affects california crops\n"
     ]
    }
   ],
   "source": [
    "print(answers_t[\"what the main idea of the text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10353\n"
     ]
    }
   ],
   "source": [
    "print(len(answers_t.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_distractors(X1,X2):\n",
    "    dists = []\n",
    "    for j in range(3):\n",
    "        in_text = \"StartSeq\"\n",
    "        for i in range(max_len):\n",
    "            sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n",
    "            sequence = pad_sequences([sequence],maxlen=max_len,padding = 'post')[0]\n",
    "            XQ = []\n",
    "            XA = []\n",
    "            XI = []\n",
    "            XQ.append(X1)\n",
    "            XA.append(X2)\n",
    "            XI.append(sequence)\n",
    "            y_pred = model.predict([np.array(XQ),np.array(XA),np.array(XI)])\n",
    "\n",
    "            if(i<=1):\n",
    "                y_pred=np.array(y_pred)\n",
    "                y_pred = y_pred.argsort()\n",
    "                y_pred=y_pred[0][:]\n",
    "                y_pred=y_pred[len(y_pred)-1-j]\n",
    "            else:\n",
    "                y_pred=y_pred.argmax()\n",
    "            word = idx_to_word[y_pred]\n",
    "            in_text += (' ' + word)\n",
    "\n",
    "            if word == 'EndSeq':\n",
    "                break\n",
    "        final_dists = in_text.split()[1:-1]\n",
    "        final_dists = ' '.join(final_dists)\n",
    "        dists.append(final_dists)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why ranju killed his father\n",
      "ranju was bad student\n",
      "WARNING:tensorflow:From /home/vyshak/anaconda3/envs/tensornlp/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question= clean_text('Why Ranju killed his father?')\n",
    "answer = clean_text('Ranju was a bad student')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(question)\n",
    "print(answer)\n",
    "seqq = [word_to_idx[wordQ] for wordQ in question.split() if wordQ in word_to_idx]\n",
    "question= pad_sequences([seqq],maxlen=max_q,value=0,padding='post')[0]\n",
    "\n",
    "seqa = [word_to_idx[wordA] for wordA in answer.split() if wordA in word_to_idx]\n",
    "answer = pad_sequences([seqa],maxlen=max_a,value=0,padding='post')[0]\n",
    "\n",
    "#   question = question.reshape((1,question.shape[0]))\n",
    "#   answer = answer.reshape((1,answer.shape[0]))\n",
    "\n",
    "\n",
    "distractor = predict_distractors(question,answer)\n",
    "distractor = str(distractor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['was taken to school', 'did like to go with his mother', 'his father did want to go with his son']\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "distractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

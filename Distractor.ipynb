{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential,Model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>distractor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meals can be served</td>\n",
       "      <td>in rooms at 9:00 p. m.</td>\n",
       "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>The local government can deal with the problem...</td>\n",
       "      <td>'If some tragedies occur again ', ' relevant d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The author called Tommy 's parents in order to</td>\n",
       "      <td>help them realize their influence on Tommy</td>\n",
       "      <td>'blame Tommy for his failing grades', 'blame T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It can be inferred from the passage that</td>\n",
       "      <td>the writer is not very willing to use idioms</td>\n",
       "      <td>'idioms are the most important part in a langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can we deal with snake wounds according to...</td>\n",
       "      <td>Stay calm and do n't move .</td>\n",
       "      <td>'Cut the wound and suck the poison out .'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                                Meals can be served   \n",
       "1           It can be inferred from the passage that   \n",
       "2     The author called Tommy 's parents in order to   \n",
       "3           It can be inferred from the passage that   \n",
       "4  How can we deal with snake wounds according to...   \n",
       "\n",
       "                                         answer_text  \\\n",
       "0                             in rooms at 9:00 p. m.   \n",
       "1  The local government can deal with the problem...   \n",
       "2         help them realize their influence on Tommy   \n",
       "3       the writer is not very willing to use idioms   \n",
       "4                        Stay calm and do n't move .   \n",
       "\n",
       "                                          distractor  \n",
       "0  'outside the room at 3:00 p. m.', 'in the dini...  \n",
       "1  'If some tragedies occur again ', ' relevant d...  \n",
       "2  'blame Tommy for his failing grades', 'blame T...  \n",
       "3  'idioms are the most important part in a langu...  \n",
       "4          'Cut the wound and suck the poison out .'  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"Train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.values\n",
    "answers = {}\n",
    "distractors = {}\n",
    "count = 0\n",
    "for x in range(train.shape[0]):\n",
    "    answers[train[x][0]] = train[x][1]\n",
    "    a=[]\n",
    "    for y in train[x][2].split(\", \"):\n",
    "        a.append(str(y[1:-1]))\n",
    "    distractors[train[x][0]] = a\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outside the room at 3:00 p. m.',\n",
       " 'in the dining - room at 6:00 p. m.',\n",
       " 'in the dining - room from 7:30 a. m. to 9:15 p. m.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distractors[\"Meals can be served\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-z0-9]+\",\" \" , sentence)\n",
    "    sentence = sentence.split()\n",
    "\n",
    "    sentence = [s for s in sentence if((len(s)>1) or (re.match(\"[0-9]+\",s) is not None))]\n",
    "    sentence = \" \".join(sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all the captions\n",
    "a={}\n",
    "d={}\n",
    "for key , dist_list in distractors.items():\n",
    "    for i in range(len(dist_list)):\n",
    "        dist_list[i] = clean_text(dist_list[i])\n",
    "    answer=clean_text(answers[key])\n",
    "    key=clean_text(key)\n",
    "    a[key]=answer\n",
    "    d[key]=dist_list\n",
    "answers=a\n",
    "distractors=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outside the room at 3 00',\n",
       " 'in the dining room at 6 00',\n",
       " 'in the dining room from 7 30 to 9 15']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distractors[\"meals can be served\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answers.txt\",\"w\") as f:\n",
    "    f.write(str(answers))\n",
    "with open(\"distractors.txt\",\"w\") as f:\n",
    "    f.write(str(distractors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21459\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for key in answers.keys():\n",
    "    [vocab.update(key.split())]\n",
    "    [vocab.update(answers[key].split())]\n",
    "    [vocab.update(sentence.split()) for sentence in distractors[key]]\n",
    "\n",
    "    \n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718584\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "for key in answers.keys():\n",
    "    [total.append(i) for i in key.split()]\n",
    "    [total.append(i) for i in answers[key].split()]\n",
    "    [total.append(i) for des in distractors[key] for i in des.split()]\n",
    "\n",
    "print(len(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4723\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter(total)\n",
    "freq_cnt = dict(counter)\n",
    "\n",
    "sorted_freq_cnt = sorted(freq_cnt.items(),reverse = True,key = lambda x:x[1])\n",
    "\n",
    "threshold =10\n",
    "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
    "total_words = [x[0] for x in sorted_freq_cnt]\n",
    "print(len(sorted_freq_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StartSeq outside the room at 3 00 EndSeq', 'StartSeq in the dining room at 6 00 EndSeq', 'StartSeq in the dining room from 7 30 to 9 15 EndSeq']\n"
     ]
    }
   ],
   "source": [
    "train_distractors = {}\n",
    "for key in distractors.keys():\n",
    "    train_distractors[key] = []\n",
    "    for dist in distractors[key]:\n",
    "        dist_to_append = \"StartSeq \" + dist + \" EndSeq\"\n",
    "        train_distractors[key].append(dist_to_append)\n",
    "        \n",
    "print(train_distractors[\"meals can be served\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4723"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4723"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "for i,word in enumerate(total_words):\n",
    "    word_to_idx[word] = i+1\n",
    "    idx_to_word[i+1] = word\n",
    "    \n",
    "len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx[\"StartSeq\"]=4724\n",
    "idx_to_word[4724] = \"StartSeq\"\n",
    "\n",
    "word_to_idx[\"EndSeq\"]=4725\n",
    "idx_to_word[4725] = \"EndSeq\"\n",
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "vocab_size= vocab_size+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4726"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "for key in train_distractors.keys():\n",
    "    for dist in train_distractors[key]:\n",
    "        max_len = max(max_len,len(dist.split()))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "max_q=0\n",
    "for key in train_distractors.keys():\n",
    "    max_q = max(max_q,len(key.split()))\n",
    "print(max_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "max_a = 0\n",
    "for key in answers.keys():\n",
    "    max_a = max(max_a,len(answers[key].split()))\n",
    "print(max_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(train_distractors,answers,word_to_idx,max_len,batch_size):\n",
    "    X1,X2,X3,y = [],[],[],[]\n",
    "\n",
    "    n=0\n",
    "    while True:\n",
    "        for key,dist_list in train_distractors.items():\n",
    "            n+=1\n",
    "\n",
    "            question = key\n",
    "            answer = answers[key]\n",
    "\n",
    "\n",
    "            seqq = [word_to_idx[wordQ] for wordQ in question.split() if wordQ in word_to_idx]\n",
    "            question= pad_sequences([seqq],maxlen=max_q,value=0,padding='post')[0]\n",
    "\n",
    "\n",
    "            seqa = [word_to_idx[wordA] for wordA in answer.split() if wordA in word_to_idx]\n",
    "            answer = pad_sequences([seqa],maxlen=max_a,value=0,padding='post')[0]\n",
    "\n",
    "            for dist in dist_list:\n",
    "                seq = [word_to_idx[word] for word in dist.split() if word in word_to_idx]\n",
    "                for i in range(1,len(seq)):\n",
    "                    xi = seq[0:i]\n",
    "                    yi = seq[i]\n",
    "\n",
    "                    xi = pad_sequences([xi],maxlen=max_len,value = 0,padding='post')[0] \n",
    "                    yi = to_categorical([yi],num_classes = vocab_size)[0]\n",
    "\n",
    "\n",
    "\n",
    "                    X1.append(question)\n",
    "                    X2.append(answer)\n",
    "                    X3.append(xi)\n",
    "                    y.append(yi)\n",
    "                if n==batch_size:\n",
    "                yield[[np.array(X1),np.array(X2),np.array(X3)],np.array(y)]\n",
    "                X1,X2,X3,y = [],[],[],[]\n",
    "                n=0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

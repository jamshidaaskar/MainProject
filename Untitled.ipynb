{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My problem is to generate some MCQ based on the paragraph given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The required modules are\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "import _pickle as cPickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = 'data/embeddings/glove.6B.300d.txt'\n",
    "tmp_file = 'data/embeddings/word2vec-glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi delhi PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ ROOT xx True True\n",
      "the the DET DT det xxx True True\n",
      "capital capital NOUN NN attr xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "India india PROPN NNP pobj Xxxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "def printGrammerPOS(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)\n",
    "    \n",
    "\n",
    "a = printGrammerPOS('Delhi is the capital of India.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'DET'], ['head', 'NOUN'], ['of', 'ADP'], ['the', 'DET'], ['pigeon', 'NOUN'], ['had', 'VERB'], ['been', 'VERB'], ['blown', 'VERB'], ['away', 'ADV'], ['with', 'ADP'], ['the', 'DET'], ['rifle', 'NOUN'], ['.', 'PUNCT']]\n"
     ]
    }
   ],
   "source": [
    "def retunPOS(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    se = []\n",
    "    lis = []\n",
    "    for token in doc:\n",
    "        se = [token.text,token.pos_]\n",
    "        lis.append(se)\n",
    "    print(lis)\n",
    "retunPOS('The head of the pigeon had been blown away with the rifle.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blown', 7]]\n"
     ]
    }
   ],
   "source": [
    "def retunVerb(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    temp = []\n",
    "    lis = []\n",
    "    se = []\n",
    "    \n",
    "    indexCount = 0\n",
    "    for token in doc:\n",
    "        if(token.pos_ == 'VERB' and not(token.is_stop)):\n",
    "            se = [token.text,indexCount]\n",
    "            \n",
    "            lis.append(se)\n",
    "        indexCount = indexCount + 1\n",
    "#     print(lis)\n",
    "    return(lis)\n",
    "a = retunVerb('The head of the pigeon had been blown away with the rifle.')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['playing', 2]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retunVerb('He is playing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' My name .......... Vyshak Puthusseri.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This can include the fill in the blanks\n",
    "def generateFillintheblanks(inputString,key):\n",
    "    stri = inputString.split() # Replace the key with index\n",
    "    stri[key[1]] = '..........'\n",
    "    output = ''\n",
    "    #combine the string \n",
    "    for i in range(len(stri)):\n",
    "        output = output + ' ' + stri[i]    \n",
    "    return(output)\n",
    "\n",
    "generateFillintheblanks('My name is Vyshak Puthusseri.',['is',2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' He is .......... in the graden'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateFillintheblanks('He is playing  in the graden ',['playing',2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blowing', 'blown', 'ripped']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the distractor\n",
    "def generateDistractor(answer,count):\n",
    "    answer = str.lower(answer)\n",
    "    \n",
    "    ##Extracting closest words for the answer. \n",
    "    try:\n",
    "        closestWords = model.most_similar(positive=[answer], topn=count)\n",
    "    except:\n",
    "        #In case the word is not in the vocabulary, or other problem not loading embeddings\n",
    "        return []\n",
    "\n",
    "    #Return count many distractors\n",
    "    distractors = list(map(lambda x: x[0], closestWords))[0:count]\n",
    "    \n",
    "    return distractors\n",
    "\n",
    "\n",
    "\n",
    "generateDistractor('blew',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionCount = 1\n",
    "def returnQuestionSet(sentence):\n",
    "    global questionCount\n",
    "    verbs = retunVerb(sentence)\n",
    "    que = generateFillintheblanks(sentence,verbs[0])\n",
    "    distractor = generateDistractor( verbs[0][0],3)\n",
    "    print(\"\\n\",questionCount,que)\n",
    "    questionCount = questionCount + 1\n",
    "    print(\"a.\",distractor[0],\"\\nb.\",distractor[1])\n",
    "    print(\"c.\",distractor[2],\"\\nd.\",verbs[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 9  My friends are .......... in the palace.\n",
      "a. eat \n",
      "b. ate\n",
      "c. eaten \n",
      "d. eating\n"
     ]
    }
   ],
   "source": [
    "returnQuestionSet('My friends are eating in the palace.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10  Your friends .......... for you for over an hour.\n",
      "a. waiting \n",
      "b. wait\n",
      "c. patiently \n",
      "d. waited\n",
      "\n",
      " 11  It is not worth .......... so much money for this concert.\n",
      "a. pay \n",
      "b. paid\n",
      "c. fees \n",
      "d. paying\n",
      "\n",
      " 12  When I .......... the station, the train had left.\n",
      "a. reaching \n",
      "b. reach\n",
      "c. reaches \n",
      "d. reached\n",
      "\n",
      " 13  I .......... the Taj Mahal last month.\n",
      "a. visit \n",
      "b. visiting\n",
      "c. traveled \n",
      "d. visited\n",
      "\n",
      " 14  The criminal .......... the victim with a blunt object.\n",
      "a. attack \n",
      "b. attacking\n",
      "c. assaulted \n",
      "d. attacked\n",
      "\n",
      " 15  His company is greatly .......... after.\n",
      "a. seeking \n",
      "b. seek\n",
      "c. tried \n",
      "d. sought\n",
      "\n",
      " 16  The terrified people .......... to the mountains.\n",
      "a. fleeing \n",
      "b. flee\n",
      "c. escaped \n",
      "d. fled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "returnQuestionSet('Your friends waited for you for over an hour.')\n",
    "returnQuestionSet('It is not worth paying so much money for this concert.')    \n",
    "returnQuestionSet('When I reached the station, the train had left.')\n",
    "returnQuestionSet('I visited the Taj Mahal last month.')\n",
    "\n",
    "returnQuestionSet('The criminal attacked the victim with a blunt object.')\n",
    "returnQuestionSet('His company is greatly sought after.')    \n",
    "returnQuestionSet('The terrified people fled to the mountains.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import unicode_literals, print_function\n",
    "# from spacy.lang.en import English # updated\n",
    "\n",
    "# raw_text = 'My name is Vyshak . Im Vyshak.'\n",
    "# nlp = English()\n",
    "# nlp.add_pipe(nlp.create_pipe('sentencizer')) # updated\n",
    "# doc = nlp(raw_text)\n",
    "# sentences = [sent.string.strip() for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayTheDependency(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    displacy.render(doc, style=\"dep\",page = \"true\",jupyter='True')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem;\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1100\" height=\"312.0\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Delhi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">capital</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">India.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayTheDependency('Delhi is the capital of India.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create  Questions with when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET DT det Xxx True False\n",
      "meeting meeting NOUN NN nsubj xxxx True False\n",
      "will will VERB MD aux xxxx True True\n",
      "be be VERB VB ROOT xx True True\n",
      "on on ADP IN prep xx True True\n",
      "monday monday PROPN NNP pobj xxxx True False\n",
      "10 10 NUM CD nummod dd False False\n",
      "am a.m. NOUN NN ccomp xx True True\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "#Parse a sentence\n",
    "sentence = \"The meeting will be on monday 10am.\"\n",
    "doc = nlp(sentence)\n",
    "# for token in doc:\n",
    "#     print(token.text, token.pos_)\n",
    "    \n",
    "# # for ent in doc.ents\n",
    "# for ent in doc.ents:\n",
    "#     ent.merge(ent.tag_, ent.text, ent.ent_type_)\n",
    "    \n",
    "    \n",
    "    \n",
    "printGrammerPOS(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars cars nsubj shift\n",
      "insurance liability liability dobj shift\n",
      "manufacturers manufacturers pobj toward\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous amod cars NOUN []\n",
      "cars nsubj shift VERB [Autonomous]\n",
      "shift ROOT shift VERB [cars, liability, toward]\n",
      "insurance compound liability NOUN []\n",
      "liability dobj shift VERB [insurance]\n",
      "toward prep shift VERB [manufacturers]\n",
      "manufacturers pobj toward ADP []\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk' has no attribute 'parse_cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d8e8ddb804cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m groucho_grammar = nltk.parse_cfg(\"\"\"\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNP\u001b[0m \u001b[0mVP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mPP\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mP\u001b[0m \u001b[0mNP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mNP\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDet\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mDet\u001b[0m \u001b[0mN\u001b[0m \u001b[0mPP\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m'I'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mVP\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mV\u001b[0m \u001b[0mNP\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mVP\u001b[0m \u001b[0mPP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nltk' has no attribute 'parse_cfg'"
     ]
    }
   ],
   "source": [
    "groucho_grammar = nltk.parse_cfg(\"\"\"\n",
    "... S -> NP VP\n",
    "... PP -> P NP\n",
    "... NP -> Det N | Det N PP | 'I'\n",
    "... VP -> V NP | VP PP\n",
    "... Det -> 'an' | 'my'\n",
    "... N -> 'elephant' | 'pajamas'\n",
    "... V -> 'shot'\n",
    "... P -> 'in'\n",
    "... \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My problem is to generate some MCQ based on the paragraph given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The required modules are\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "import _pickle as cPickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "#For loading the glove\n",
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = 'data/embeddings/glove.6B.300d.txt'\n",
    "tmp_file = 'data/embeddings/word2vec-glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi delhi PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ ROOT xx True True\n",
      "the the DET DT det xxx True True\n",
      "capital capital NOUN NN attr xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "India india PROPN NNP pobj Xxxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "def printGrammerPOS(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)\n",
    "    \n",
    "\n",
    "a = printGrammerPOS('Delhi is the capital of India.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'DET'], ['head', 'NOUN'], ['of', 'ADP'], ['the', 'DET'], ['pigeon', 'NOUN'], ['had', 'VERB'], ['been', 'VERB'], ['blown', 'VERB'], ['away', 'ADV'], ['with', 'ADP'], ['the', 'DET'], ['rifle', 'NOUN'], ['.', 'PUNCT']]\n"
     ]
    }
   ],
   "source": [
    "def retunPOS(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    se = []\n",
    "    lis = []\n",
    "    for token in doc:\n",
    "        se = [token.text,token.pos_]\n",
    "        lis.append(se)\n",
    "    print(lis)\n",
    "retunPOS('The head of the pigeon had been blown away with the rifle.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['blown', 7]]\n"
     ]
    }
   ],
   "source": [
    "def retunVerb(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    temp = []\n",
    "    lis = []\n",
    "    se = []\n",
    "    \n",
    "    indexCount = 0\n",
    "    for token in doc:\n",
    "        if(token.pos_ == 'VERB' and not(token.is_stop)):\n",
    "            se = [token.text,indexCount]\n",
    "            \n",
    "            lis.append(se)\n",
    "        indexCount = indexCount + 1\n",
    "#     print(lis)\n",
    "    return(lis)\n",
    "a = retunVerb('The head of the pigeon had been blown away with the rifle.')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['head', 1], ['pigeon', 4], ['rifle', 11]]\n"
     ]
    }
   ],
   "source": [
    "def returnNoun(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    lis = []\n",
    "    se = []\n",
    "    indexCount = 0\n",
    "    for token in doc:\n",
    "        if(token.pos_ =='NOUN' and not(token.is_stop)):\n",
    "            se = [token.text,indexCount]\n",
    "            lis.append(se)\n",
    "        indexCount = indexCount + 1\n",
    "    print(lis)\n",
    "    \n",
    "    \n",
    "returnNoun('The head of the pigeon had been blown away with the rifle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' My name .......... Vyshak Puthusseri.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This can include the fill in the blanks\n",
    "def generateFillintheblanks(inputString,key):\n",
    "    stri = inputString.split() # Replace the key with index\n",
    "    stri[key[1]] = '..........'\n",
    "    output = ''\n",
    "    #combine the string \n",
    "    for i in range(len(stri)):\n",
    "        output = output + ' ' + stri[i]    \n",
    "    return(output)\n",
    "\n",
    "generateFillintheblanks('My name is Vyshak Puthusseri.',['is',2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blowing', 'blown', 'ripped', 'exploded']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the distractor\n",
    "def generateDistractor(answer,count):\n",
    "    '''I had choosed the verb as the key , so the most similar words in the glove will result the \n",
    "    other forms of the current word, a simple technique for the distractor.'''\n",
    "    answer = str.lower(answer)\n",
    "    \n",
    "    ##Extracting closest words for the answer. \n",
    "    try:\n",
    "        closestWords = model.most_similar(positive=[answer], topn=count)\n",
    "    except:\n",
    "        #In case the word is not in the vocabulary, or other problem not loading embeddings\n",
    "        return []\n",
    "    #Return count many distractors\n",
    "    distractors = list(map(lambda x: x[0], closestWords))[0:count]\n",
    "    return distractors\n",
    "\n",
    "generateDistractor('blew',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  My friends are .......... in the palace.\n",
      "a. ran \n",
      "b. run\n",
      "c. line \n",
      "d. running\n"
     ]
    }
   ],
   "source": [
    "questionCount = 1\n",
    "def returnQuestionSet(sentence):\n",
    "    global questionCount\n",
    "    verbs = retunVerb(sentence)\n",
    "    que = generateFillintheblanks(sentence,verbs[0])\n",
    "    distractor = generateDistractor( verbs[0][0],3)\n",
    "    print(\"\\n\",questionCount,que)\n",
    "    questionCount = questionCount + 1\n",
    "    print(\"a.\",distractor[0],\"\\nb.\",distractor[1])\n",
    "    print(\"c.\",distractor[2],\"\\nd.\",verbs[0][0])\n",
    "\n",
    "returnQuestionSet('My friends are running in the palace.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  Your friends .......... for you for over an hour.\n",
      "a. waiting \n",
      "b. wait\n",
      "c. patiently \n",
      "d. waited\n",
      "\n",
      " 3  It is not worth .......... so much money for this concert.\n",
      "a. pay \n",
      "b. paid\n",
      "c. fees \n",
      "d. paying\n",
      "\n",
      " 4  When I .......... the station, the train had left.\n",
      "a. reaching \n",
      "b. reach\n",
      "c. reaches \n",
      "d. reached\n",
      "\n",
      " 5  I .......... the Taj Mahal last month.\n",
      "a. visit \n",
      "b. visiting\n",
      "c. traveled \n",
      "d. visited\n",
      "\n",
      " 6  The criminal .......... the victim with a blunt object.\n",
      "a. attack \n",
      "b. attacking\n",
      "c. assaulted \n",
      "d. attacked\n",
      "\n",
      " 7  His company is greatly .......... after.\n",
      "a. seeking \n",
      "b. seek\n",
      "c. tried \n",
      "d. sought\n",
      "\n",
      " 8  The terrified people .......... to the mountains.\n",
      "a. fleeing \n",
      "b. flee\n",
      "c. escaped \n",
      "d. fled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "returnQuestionSet('Your friends waited for you for over an hour.')\n",
    "returnQuestionSet('It is not worth paying so much money for this concert.')    \n",
    "returnQuestionSet('When I reached the station, the train had left.')\n",
    "returnQuestionSet('I visited the Taj Mahal last month.')\n",
    "\n",
    "returnQuestionSet('The criminal attacked the victim with a blunt object.')\n",
    "returnQuestionSet('His company is greatly sought after.')    \n",
    "returnQuestionSet('The terrified people fled to the mountains.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return all the question sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  My friends are .......... in the palace.\n",
      "a. eat \n",
      "b. ate\n",
      "c. eaten \n",
      "d. eating\n",
      "\n",
      " 1  Your friends .......... for you for over an hour.\n",
      "a. waiting \n",
      "b. wait\n",
      "c. patiently \n",
      "d. waited\n",
      "\n",
      " 2  It is not worth .......... so much money for this concert.\n",
      "a. pay \n",
      "b. paid\n",
      "c. fees \n",
      "d. paying\n",
      "\n",
      " 3  When I .......... the station, the train had left.\n",
      "a. reaching \n",
      "b. reach\n",
      "c. reaches \n",
      "d. reached\n",
      "\n",
      " 4  I .......... the Taj Mahal last month.\n",
      "a. visit \n",
      "b. visiting\n",
      "c. traveled \n",
      "d. visited\n",
      "\n",
      " 5  The criminal .......... the victim with a blunt object.\n",
      "a. attack \n",
      "b. attacking\n",
      "c. assaulted \n",
      "d. attacked\n",
      "\n",
      " 6  His company is greatly .......... after.\n",
      "a. seeking \n",
      "b. seek\n",
      "c. tried \n",
      "d. sought\n",
      "\n",
      " 7  The terrified people .......... to the mountains.\n",
      "a. fleeing \n",
      "b. flee\n",
      "c. escaped \n",
      "d. fled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  ' My friends are .......... in the palace.',\n",
       "  'eat',\n",
       "  'ate',\n",
       "  'eaten',\n",
       "  'eating'],\n",
       " [2,\n",
       "  ' Your friends .......... for you for over an hour.',\n",
       "  'waiting',\n",
       "  'wait',\n",
       "  'patiently',\n",
       "  'waited'],\n",
       " [3,\n",
       "  ' It is not worth .......... so much money for this concert.',\n",
       "  'pay',\n",
       "  'paid',\n",
       "  'fees',\n",
       "  'paying'],\n",
       " [4,\n",
       "  ' When I .......... the station, the train had left.',\n",
       "  'reaching',\n",
       "  'reach',\n",
       "  'reaches',\n",
       "  'reached'],\n",
       " [5,\n",
       "  ' I .......... the Taj Mahal last month.',\n",
       "  'visit',\n",
       "  'visiting',\n",
       "  'traveled',\n",
       "  'visited'],\n",
       " [6,\n",
       "  ' The criminal .......... the victim with a blunt object.',\n",
       "  'attack',\n",
       "  'attacking',\n",
       "  'assaulted',\n",
       "  'attacked'],\n",
       " [7,\n",
       "  ' His company is greatly .......... after.',\n",
       "  'seeking',\n",
       "  'seek',\n",
       "  'tried',\n",
       "  'sought'],\n",
       " [8,\n",
       "  ' The terrified people .......... to the mountains.',\n",
       "  'fleeing',\n",
       "  'flee',\n",
       "  'escaped',\n",
       "  'fled']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retun quesion set from a sentence\n",
    "questionCount = 0\n",
    "def returnQuestionSetasList(sentence):\n",
    "    global questionCount\n",
    "    verbs = retunVerb(sentence)\n",
    "    que = generateFillintheblanks(sentence,verbs[0])\n",
    "    distractor = generateDistractor( verbs[0][0],3)\n",
    "    print(\"\\n\",questionCount,que)\n",
    "    print(\"a.\",distractor[0],\"\\nb.\",distractor[1])\n",
    "    print(\"c.\",distractor[2],\"\\nd.\",verbs[0][0])\n",
    "    questionCount = questionCount + 1\n",
    "    li = []\n",
    "    li.append(questionCount)\n",
    "    li.append(que)\n",
    "    li.append(distractor[0])\n",
    "    li.append(distractor[1])\n",
    "    li.append(distractor[2])\n",
    "    li.append(verbs[0][0])\n",
    "    return li\n",
    "\n",
    "\n",
    "# Now given a paragraph , return all the quesions\n",
    "def returnAllQuestions(paragraph):\n",
    "    \"This can be directly use inside the flask for displaying the result. Just use a for loop to traverse.\"\n",
    "    li = []\n",
    "    sentences = sent_tokenize(para)\n",
    "    for sentence in sentences:\n",
    "        li.append(returnQuestionSetasList(sentence))\n",
    "    return(li)\n",
    "returnAllQuestions(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispay the delpendencies using the displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem;\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1100\" height=\"312.0\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Delhi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">capital</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">India.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def displayTheDependency(inputString):\n",
    "    doc = nlp(inputString)\n",
    "    displacy.render(doc, style=\"dep\",page = \"true\",jupyter='True')\n",
    " \n",
    "\n",
    "displayTheDependency('Delhi is the capital of India.')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

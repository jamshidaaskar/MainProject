{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert==0.6.2\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 406 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.6.2) (4.42.0)\n",
      "Requirement already satisfied: numpy in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.6.2) (1.18.1)\n",
      "Requirement already satisfied: requests in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.6.2) (2.22.0)\n",
      "Requirement already satisfied: regex in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.6.2) (2019.12.9)\n",
      "Collecting torch>=0.4.1\n",
      "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4 MB 4.4 kB/s eta 0:00:014   |██                              | 47.8 MB 1.6 MB/s eta 0:07:18     |████                            | 91.7 MB 1.6 MB/s eta 0:06:43     |████████████████▍               | 386.8 MB 1.6 MB/s eta 0:03:56\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pytorch-pretrained-bert==0.6.2) (1.11.13)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.6.2) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.6.2) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.6.2) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert==0.6.2) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert==0.6.2) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.13 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert==0.6.2) (1.14.13)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert==0.6.2) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.13->boto3->pytorch-pretrained-bert==0.6.2) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.13->boto3->pytorch-pretrained-bert==0.6.2) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.13->boto3->pytorch-pretrained-bert==0.6.2) (1.14.0)\n",
      "Installing collected packages: torch, pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2 torch-1.4.0\n",
      "Collecting git+https://github.com/boudinfl/pke.git\n",
      "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-n23y9vos\n",
      "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-n23y9vos\n",
      "Requirement already satisfied: nltk in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pke==1.8.1) (3.4.5)\n",
      "Collecting networkx\n",
      "  Using cached networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: numpy in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pke==1.8.1) (1.18.1)\n",
      "Requirement already satisfied: scipy in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pke==1.8.1) (1.4.1)\n",
      "Requirement already satisfied: spacy in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pke==1.8.1) (2.0.16)\n",
      "Requirement already satisfied: six in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pke==1.8.1) (1.14.0)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
      "\u001b[K     |████████████████████████████████| 238 kB 492 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from pke==1.8.1) (0.14.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from networkx->pke==1.8.1) (4.4.1)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (0.4.3.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (2.0.2)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (2.0.1)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (6.12.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (0.9.6)\n",
      "Requirement already satisfied: ujson>=1.35 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (1.35)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (0.2.9)\n",
      "Collecting regex==2018.01.10\n",
      "  Downloading regex-2018.01.10.tar.gz (612 kB)\n",
      "\u001b[K     |████████████████████████████████| 612 kB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from spacy->pke==1.8.1) (2.22.0)\n",
      "Requirement already satisfied: scikit-learn in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from sklearn->pke==1.8.1) (0.22.1)\n",
      "Requirement already satisfied: msgpack>=0.3.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from msgpack-numpy<0.4.4->spacy->pke==1.8.1) (0.6.1)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.0->spacy->pke==1.8.1) (0.9.0.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.0->spacy->pke==1.8.1) (1.10.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.0->spacy->pke==1.8.1) (4.42.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2019.11.28)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.0->spacy->pke==1.8.1) (0.10.0)\n",
      "Building wheels for collected packages: pke, sklearn, future, regex\n",
      "  Building wheel for pke (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pke: filename=pke-1.8.1-py3-none-any.whl size=8754518 sha256=f598f31afd9c7554c6e3e32277fd19032c50458c7b2a6404a6bd3778f99cbbde\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s3jl_98e/wheels/fa/b3/09/612ee93bf3ee4164bcd5783e742942cdfc892a86039d3e0a33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=fa82a4f634e973655edcc71a84d6e74be7eb0e4c21342786e7e3f268e11d9ff1\n",
      "  Stored in directory: /home/vyshak/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=e442277b6f45a8b47eaaa50428c040930a44cdda4cb4ac46c2b5966043bcb723\n",
      "  Stored in directory: /home/vyshak/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for regex: filename=regex-2018.1.10-cp37-cp37m-linux_x86_64.whl size=552461 sha256=237d13b81fb5837752f81ba2074e7d82e95b1986db721265501ebdb50af1413a\n",
      "  Stored in directory: /home/vyshak/.cache/pip/wheels/ba/ec/25/0c2b801e792098f7dad5b76157b01be8d0719525c365773e7c\n",
      "Successfully built pke sklearn future regex\n",
      "Installing collected packages: networkx, sklearn, unidecode, future, pke, regex\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2019.12.9\n",
      "    Uninstalling regex-2019.12.9:\n",
      "      Successfully uninstalled regex-2019.12.9\n",
      "Successfully installed future-0.18.2 networkx-2.4 pke-1.8.1 regex-2018.1.10 sklearn-0.0 unidecode-1.1.1\n",
      "Collecting flashtext\n",
      "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
      "Building wheels for collected packages: flashtext\n",
      "  Building wheel for flashtext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9299 sha256=c365cb2c4177cf892ed73ddb676a7bd0f5422497e630319d99a1a9ff13898e49\n",
      "  Stored in directory: /home/vyshak/.cache/pip/wheels/cb/19/58/4e8fdd0009a7f89dbce3c18fff2e0d0fa201d5cdfd16f113b7\n",
      "Successfully built flashtext\n",
      "Installing collected packages: flashtext\n",
      "Successfully installed flashtext-2.7\n",
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/vyshak/anaconda3/envs/nlp/lib/python3.7/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n",
      "/home/vyshak/anaconda3/envs/nlp/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/vyshak/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
     ]
    }
   ],
   "source": [
    "# !pip install pytorch-pretrained-bert==0.6.2\n",
    "# !pip install git+https://github.com/boudinfl/pke.git\n",
    "# !pip install flashtext\n",
    "# !python -m spacy download en\n",
    "# !python -m nltk.downloader universal_tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 248311.12B/s]\n",
      "100%|██████████| 407873900/407873900 [02:32<00:00, 2674532.88B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed to load BERT  163.9032962322235\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer,BertForMaskedLM\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "import time\n",
    "start = time.time()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "end = time.time()\n",
    "print (\"Time Elapsed to load BERT \",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence:  They all look tiny ____ they are so far away from the Earth. \n",
      "\n",
      "predicted choices:  ['because', 'and', 'but', 'as', 'since', 'like', 'when', 'considering', 'for', 'except', 'though', 'that', 'yet', 'although', 'while', 'now', 'if', 'where', 'here', 'even', 'so', 'after', 'from', 'given']\n"
     ]
    }
   ],
   "source": [
    "def get_predicted_words(text):\n",
    "    text = \"[CLS] \" + text.replace(\"____\", \"[MASK]\") + \" [SEP]\"\n",
    "    # text= '[CLS] Tom has fully [MASK] from his illness. [SEP]'\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    #print(\"tokenized sentence: \",tokenized_text,\"\\n\")\n",
    "    masked_index = tokenized_text.index('[MASK]')\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Create the segments tensors.\n",
    "    segments_ids = [0] * len(tokenized_text)\n",
    "# Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "# Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        predictions = model(tokens_tensor, segments_tensors)\n",
    "# Get 30 choices for the masked(blank) word \n",
    "    k = 30\n",
    "    predicted_index, predicted_index_values = torch.topk(predictions[0, masked_index], k)\n",
    "    predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_index_values.tolist())\n",
    "    filtered_tokens_to_remove_punctuation = []\n",
    "    # Remove any predictions that contain punctuation etc as they are not relevant to us.\n",
    "    for token in predicted_tokens:\n",
    "        if re.match(\"^[a-zA-Z0-9_]*$\", token):\n",
    "            filtered_tokens_to_remove_punctuation.append(token)\n",
    "        \n",
    "    return filtered_tokens_to_remove_punctuation\n",
    "sentence = \"They all look tiny ____ they are so far away from the Earth.\"\n",
    "print (\"original sentence: \",sentence,\"\\n\")\n",
    "predicted_words = get_predicted_words(sentence)\n",
    "print (\"predicted choices: \", predicted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
